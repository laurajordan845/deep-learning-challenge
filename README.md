# deep-learning-challenge
Module 21 Neural Networks and Deep Learning Challenge for Laura Jordan

## Description
The nonprofit foundation Alphabet Soup wants a tool that can help it select the applicants for funding with the best chance of success in their ventures. The analysis had the primary goal of creating a binary classifier that can predict whether applicants would be successful if funded by Alphabet Soup. 

The challenge included 5 steps:
* Preprocess the Data
* Compile, Train, and Evaluate the Model
* Optimize the Model
* Write a Report on the Neural Network Model
* Copy Files Into Your Repository

## Support
I attended class, reviewed our in-class activities, read through my notes and did a lot of online research for the support needed for this challenge assignment. For assistance with adding a callback that saves the model's weights every five epochs, I consulted several questions and answers in Stack Overflow.

## Submission Includes
* Jupyter Notebook: Module 21 - LJordan.ipynb
* 3 attempts to optimize the model using Google Colab:
    *  AlphabetSoupCharity_Optimization_1
    *  AlphabetSoupCharity_Optimization_2
    *  AlphabetSoupCharity_Optimization_3
*  Each attempt to optimize the model had two additional pieces:
    *  Export of the model to HDF5 file
        * AlphabetSoupCharity-1.h5
        * AlphabetSoupCharity-2.h5
        * AlphabetSoupCharity-3.h5
     * Callback that saves the model's weight every 5 epochs for each model
        * checkpoints-Optimization1 folder
        * checkpoints-Optimization2 folder   
        * checkpoints-Optimization3 folder
* Readme file with the Report on the Neural Network Model: [Link to Analysis](https://github.com/laurajordan845/deep-learning-challenge/blob/main/Written_Analysis.md)
* Resources folder which houses the charity_data.csv file with the dataset (although for the model, I pulled it from it's online version)

